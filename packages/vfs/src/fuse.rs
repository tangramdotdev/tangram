use {
	self::sys::{
		fuse_attr, fuse_attr_out, fuse_batch_forget_in, fuse_entry_out, fuse_flush_in,
		fuse_forget_in, fuse_getattr_in, fuse_getxattr_in, fuse_getxattr_out, fuse_in_header,
		fuse_init_in, fuse_init_out, fuse_open_in, fuse_open_out, fuse_out_header, fuse_read_in,
		fuse_release_in,
	},
	crate::{FileType, Provider, Result},
	bytes::Bytes,
	num::ToPrimitive as _,
	std::{
		ffi::CString,
		io::{Error, IoSlice},
		mem::MaybeUninit,
		ops::Deref,
		os::{
			fd::{AsFd as _, AsRawFd as _, BorrowedFd, OwnedFd},
			unix::process::CommandExt as _,
		},
		path::Path,
		sync::{
			Arc, Mutex,
			atomic::{AtomicBool, Ordering},
		},
	},
	sys::{FUSE_KERNEL_MINOR_VERSION, FUSE_KERNEL_VERSION, fuse_interrupt_in},
};

#[allow(warnings)]
pub mod sys;

// FUSE device ioctl opcodes. These are defined as C macros in fuse.h and are not generated by
// bindgen. The values are computed using rustix's opcode helpers to match the kernel definitions.
const FUSE_DEV_IOC_CLONE: rustix::ioctl::Opcode = rustix::ioctl::opcode::read::<u32>(229, 0); // _IOR(229, 0, uint32_t)
const FUSE_DEV_IOC_BACKING_OPEN: rustix::ioctl::Opcode =
	rustix::ioctl::opcode::write::<fuse_backing_map>(229, 1); // _IOW(229, 1, struct fuse_backing_map)

// Errno constants for FUSE error handling.
const ENODATA: i32 = rustix::io::Errno::NODATA.raw_os_error();
const ENOENT: i32 = rustix::io::Errno::NOENT.raw_os_error();
const ENOSYS: i32 = rustix::io::Errno::NOSYS.raw_os_error();
const ERANGE: i32 = rustix::io::Errno::RANGE.raw_os_error();

// The number of concurrent io_uring Read SQEs per worker thread.
const READ_CONCURRENCY: u64 = 32;

// Token constants for io_uring completions. Read tokens use 0..READ_CONCURRENCY-1.
const EVENTFD_TOKEN: u64 = READ_CONCURRENCY;
const WRITE_TOKEN_BASE: u64 = 0x1000_0000;

// Linux poll event constant.
const POLLIN: u32 = 0x0001;

// Mode type constants for FUSE attribute encoding.
const S_IFDIR: u32 = 0o040_000;
const S_IFREG: u32 = 0o100_000;
const S_IFLNK: u32 = 0o120_000;

// Local fixed-size versions of fuse_dirent and fuse_direntplus. The bindgen versions have a
// flexible array member for the name, which prevents them from implementing Copy and zerocopy
// traits. These are used as headers during serialization; the name bytes are appended separately.
#[repr(C)]
#[derive(Clone, Copy, Debug)]
struct fuse_dirent {
	ino: u64,
	off: u64,
	namelen: u32,
	type_: u32,
}

#[repr(C)]
#[derive(Clone, Copy, Debug)]
struct fuse_direntplus {
	entry_out: fuse_entry_out,
	dirent: fuse_dirent,
}

// Local fuse_backing_map for the passthrough ioctl.
#[repr(C)]
struct fuse_backing_map {
	fd: i32,
	flags: u32,
	padding: u64,
}

/// Custom ioctl for `FUSE_DEV_IOC_BACKING_OPEN` that captures the backing id from the return value.
struct BackingOpenIoctl(fuse_backing_map);

unsafe impl rustix::ioctl::Ioctl for BackingOpenIoctl {
	type Output = i32;

	const IS_MUTATING: bool = false;

	fn opcode(&self) -> rustix::ioctl::Opcode {
		FUSE_DEV_IOC_BACKING_OPEN
	}

	fn as_ptr(&mut self) -> *mut std::ffi::c_void {
		std::ptr::addr_of_mut!(self.0).cast()
	}

	unsafe fn output_from_ptr(
		out: rustix::ioctl::IoctlOutput,
		_ptr: *mut std::ffi::c_void,
	) -> rustix::io::Result<i32> {
		Ok(out)
	}
}

pub struct Server<P>(Arc<Inner<P>>);

pub struct Inner<P> {
	provider: P,
	task: Mutex<Option<tangram_futures::task::Shared<()>>>,
}

/// A request.
#[derive(Clone, Debug)]
struct Request {
	header: sys::fuse_in_header,
	data: RequestData,
}

/// A request's data.
#[derive(Clone, Debug)]
enum RequestData {
	BatchForget(sys::fuse_batch_forget_in),
	Destroy,
	Flush(sys::fuse_flush_in),
	Forget(sys::fuse_forget_in),
	GetAttr(sys::fuse_getattr_in),
	GetXattr(sys::fuse_getxattr_in, CString),
	Init(sys::fuse_init_in),
	ListXattr(sys::fuse_getxattr_in),
	Lookup(CString),
	Open(sys::fuse_open_in),
	OpenDir(sys::fuse_open_in),
	Read(sys::fuse_read_in),
	ReadDir(sys::fuse_read_in),
	ReadDirPlus(sys::fuse_read_in),
	ReadLink,
	Release(sys::fuse_release_in),
	ReleaseDir(sys::fuse_release_in),
	Statfs,
	Statx(sys::fuse_statx_in),
	Interrupt(sys::fuse_interrupt_in),
	Unsupported(u32),
}

/// A response.
#[derive(Clone, Debug)]
enum Response {
	Flush,
	GetAttr(sys::fuse_attr_out),
	GetXattr(Vec<u8>),
	Init(sys::fuse_init_out),
	ListXattr(Vec<u8>),
	Lookup(sys::fuse_entry_out),
	Open(sys::fuse_open_out),
	OpenDir(sys::fuse_open_out),
	Read(Bytes),
	ReadDir(Vec<u8>),
	ReadDirPlus(Vec<u8>),
	ReadLink(CString),
	Release,
	ReleaseDir,
	Statfs(sys::fuse_statfs_out),
	Statx(sys::fuse_statx_out),
}

/// The result of trying to handle a request synchronously.
enum SyncResult {
	/// The request was handled and a response should be sent.
	Response(Result<Option<Response>>),
	/// The request does not produce a response (e.g., FORGET).
	NoResponse,
	/// The request needs async handling.
	NeedAsync(Request),
}

/// The features negotiated during INIT.
struct Features {
	passthrough: bool,
	no_opendir: bool,
}

impl<P> Server<P>
where
	P: Provider + Send + Sync + 'static,
{
	pub async fn start(provider: P, path: &Path, num_workers: usize) -> Result<Self> {
		// Create the server.
		let server = Self(Arc::new(Inner {
			provider,
			task: Mutex::new(None),
		}));

		// Unmount.
		unmount(path).await.ok();

		// Mount.
		let fd = Self::mount(path)
			.await
			.inspect_err(|error| tracing::error!(%error, "failed to mount"))?;

		// Perform the INIT handshake synchronously on the original fd.
		let features = Self::init_handshake(fd.as_ref())?;

		// Clone the fd for each worker thread via FUSE_DEV_IOC_CLONE.
		let mut worker_fds = Vec::with_capacity(num_workers);
		for _ in 0..num_workers {
			worker_fds.push(clone_fuse_fd(&fd)?);
		}

		// Create the stop flag.
		let stop_flag = Arc::new(AtomicBool::new(false));

		// Capture the tokio runtime handle so worker threads can spawn async tasks.
		let runtime_handle = tokio::runtime::Handle::current();

		// Spawn worker threads.
		let mut worker_handles = Vec::with_capacity(num_workers);
		let features = Arc::new(features);
		for worker_fd in worker_fds {
			let server = server.clone();
			let stop_flag = stop_flag.clone();
			let features = features.clone();
			let original_fd = fd.clone();
			let runtime_handle = runtime_handle.clone();
			let handle = std::thread::spawn(move || {
				let result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
					worker_thread_loop(
						&server,
						&worker_fd,
						&original_fd,
						&stop_flag,
						&features,
						&runtime_handle,
					);
				}));
				if let Err(error) = result {
					let message = error
						.downcast_ref::<String>()
						.map(String::as_str)
						.or(error.downcast_ref::<&str>().copied());
					tracing::error!(?message, "worker thread panicked");
				}
			});
			worker_handles.push(handle);
		}

		// Spawn the lifecycle task.
		let path = path.to_owned();
		let task = tangram_futures::task::Shared::spawn(move |stop| {
			let stop_flag = stop_flag.clone();
			async move {
				stop.wait().await;
				stop_flag.store(true, Ordering::SeqCst);
				unmount(&path)
					.await
					.inspect_err(|error| tracing::error!(%error, "failed to unmount"))
					.ok();
				// Join all worker threads.
				tokio::task::spawn_blocking(move || {
					for handle in worker_handles {
						handle.join().ok();
					}
				})
				.await
				.ok();
			}
		});
		server.task.lock().unwrap().replace(task);

		Ok(server)
	}

	pub fn stop(&self) {
		self.task.lock().unwrap().as_ref().unwrap().stop();
	}

	pub async fn wait(&self) {
		let task = self.task.lock().unwrap().clone().unwrap();
		task.wait().await.unwrap();
	}

	/// Perform the FUSE INIT handshake on the given fd.
	fn init_handshake(fd: &OwnedFd) -> Result<Features> {
		// Read the INIT request.
		let mut buffer = vec![0u8; 1024 * 1024 + 4096];
		let n = rustix::io::read(fd, &mut buffer[..])?;
		let request = Self::deserialize_request(&buffer[..n])?;
		let RequestData::Init(init_in) = request.data else {
			return Err(Error::other("expected INIT request"));
		};

		// Check the kernel's flags.
		let kernel_flags =
			init_in.flags.to_u64().unwrap() | (init_in.flags2.to_u64().unwrap() << 32);
		let passthrough = kernel_flags & sys::FUSE_PASSTHROUGH != 0;

		// Build our desired flags.
		let mut flags: u64 = u64::from(
			sys::FUSE_DO_READDIRPLUS
				| sys::FUSE_ASYNC_READ
				| sys::FUSE_PARALLEL_DIROPS
				| sys::FUSE_CACHE_SYMLINKS
				| sys::FUSE_SPLICE_READ
				| sys::FUSE_SPLICE_MOVE
				| sys::FUSE_NO_OPENDIR_SUPPORT
				| sys::FUSE_INIT_EXT,
		);
		if passthrough {
			flags |= sys::FUSE_PASSTHROUGH;
		}

		// Only request features the kernel supports.
		flags &= kernel_flags;

		let flags_lo = (flags & 0xFFFF_FFFF) as u32;
		let flags_hi = (flags >> 32) as u32;

		let response = fuse_init_out {
			major: FUSE_KERNEL_VERSION,
			minor: FUSE_KERNEL_MINOR_VERSION,
			max_readahead: 1024 * 1024,
			flags: flags_lo,
			max_background: 0,
			congestion_threshold: 0,
			max_write: 4096,
			time_gran: 0,
			max_pages: 0,
			map_alignment: 0,
			flags2: flags_hi,
			max_stack_depth: 0,
			request_timeout: 0,
			unused: [0; 11],
		};

		// Write the INIT response.
		let init_response = Response::Init(response);
		write_response(fd.as_fd(), request.header.unique, &init_response)?;

		let passthrough_enabled = flags & sys::FUSE_PASSTHROUGH != 0;
		let no_opendir = flags & u64::from(sys::FUSE_NO_OPENDIR_SUPPORT) != 0;

		Ok(Features {
			passthrough: passthrough_enabled,
			no_opendir,
		})
	}

	fn deserialize_request(buffer: &[u8]) -> Result<Request> {
		let header: fuse_in_header = read_data(buffer)?;
		let header_len = std::mem::size_of::<sys::fuse_in_header>();
		let data = &buffer[header_len..];
		let data = match header.opcode {
			sys::fuse_opcode_FUSE_BATCH_FORGET => RequestData::BatchForget(read_data(data)?),
			sys::fuse_opcode_FUSE_DESTROY => RequestData::Destroy,
			sys::fuse_opcode_FUSE_FLUSH => RequestData::Flush(read_data(data)?),
			sys::fuse_opcode_FUSE_FORGET => RequestData::Forget(read_data(data)?),
			sys::fuse_opcode_FUSE_GETATTR => RequestData::GetAttr(read_data(data)?),
			sys::fuse_opcode_FUSE_GETXATTR => {
				let (fuse_getxattr_in, name) =
					data.split_at(std::mem::size_of::<sys::fuse_getxattr_in>());
				let fuse_getxattr_in = read_data(fuse_getxattr_in)?;
				let name = CString::from_vec_with_nul(name.to_owned())
					.map_err(|_| Error::other("failed to deserialize request data"))?;
				RequestData::GetXattr(fuse_getxattr_in, name)
			},
			sys::fuse_opcode_FUSE_INIT => RequestData::Init(read_data(data)?),
			sys::fuse_opcode_FUSE_LISTXATTR => RequestData::ListXattr(read_data(data)?),
			sys::fuse_opcode_FUSE_LOOKUP => {
				let data = CString::from_vec_with_nul(data.to_owned())
					.map_err(|_| Error::other("failed to deserialize request data"))?;
				RequestData::Lookup(data)
			},
			sys::fuse_opcode_FUSE_OPEN => RequestData::Open(read_data(data)?),
			sys::fuse_opcode_FUSE_OPENDIR => RequestData::OpenDir(read_data(data)?),
			sys::fuse_opcode_FUSE_READ => RequestData::Read(read_data(data)?),
			sys::fuse_opcode_FUSE_READDIR => RequestData::ReadDir(read_data(data)?),
			sys::fuse_opcode_FUSE_READDIRPLUS => RequestData::ReadDirPlus(read_data(data)?),
			sys::fuse_opcode_FUSE_READLINK => RequestData::ReadLink,
			sys::fuse_opcode_FUSE_RELEASE => RequestData::Release(read_data(data)?),
			sys::fuse_opcode_FUSE_RELEASEDIR => RequestData::ReleaseDir(read_data(data)?),
			sys::fuse_opcode_FUSE_STATFS => RequestData::Statfs,
			sys::fuse_opcode_FUSE_STATX => RequestData::Statx(read_data(data)?),
			sys::fuse_opcode_FUSE_INTERRUPT => RequestData::Interrupt(read_data(data)?),
			_ => RequestData::Unsupported(header.opcode),
		};
		let request = Request { header, data };
		Ok(request)
	}

	fn try_handle_sync(
		&self,
		request: &Request,
		original_fd: &OwnedFd,
		features: &Features,
	) -> SyncResult {
		match &request.data {
			// INIT is handled before workers start.
			RequestData::Init(..) => unreachable!(),

			// These requests do not produce a response.
			RequestData::Forget(..)
			| RequestData::BatchForget(..)
			| RequestData::Destroy
			| RequestData::Interrupt(..) => SyncResult::NoResponse,

			// Flush and release are trivially handled.
			RequestData::Flush(..) => SyncResult::Response(Ok(Some(Response::Flush))),
			RequestData::Release(data) => {
				self.provider.close_sync(data.fh);
				SyncResult::Response(Ok(Some(Response::Release)))
			},
			RequestData::ReleaseDir(data) => {
				self.provider.close_sync(data.fh);
				SyncResult::Response(Ok(Some(Response::ReleaseDir)))
			},

			// Try sync getattr.
			RequestData::GetAttr(..) => match self.provider.getattr_sync(request.header.nodeid) {
				Err(e) if e.raw_os_error() == Some(ENOSYS) => {
					SyncResult::NeedAsync(request.clone())
				},
				result => SyncResult::Response(result.map(|attr| {
					Some(Response::GetAttr(make_fuse_attr_out(
						request.header.nodeid,
						&attr,
					)))
				})),
			},

			// Try sync lookup.
			RequestData::Lookup(name) => {
				let Ok(name_str) = name.to_str() else {
					return SyncResult::Response(Err(Error::from_raw_os_error(ENOENT)));
				};
				match self.provider.lookup_sync(request.header.nodeid, name_str) {
					Err(e) if e.raw_os_error() == Some(ENOSYS) => {
						SyncResult::NeedAsync(request.clone())
					},
					Ok(Some(node)) => match self.provider.getattr_sync(node) {
						Err(e) if e.raw_os_error() == Some(ENOSYS) => {
							SyncResult::NeedAsync(request.clone())
						},
						Ok(attr) => SyncResult::Response(Ok(Some(Response::Lookup(
							make_fuse_entry_out(node, &attr),
						)))),
						Err(e) => SyncResult::Response(Err(e)),
					},
					Ok(None) => SyncResult::Response(Err(Error::from_raw_os_error(ENOENT))),
					Err(e) => SyncResult::Response(Err(e)),
				}
			},

			// Try sync open with passthrough support.
			RequestData::Open(..) => {
				match self.provider.open_sync(request.header.nodeid) {
					Err(e) if e.raw_os_error() == Some(ENOSYS) => {
						SyncResult::NeedAsync(request.clone())
					},
					Ok((fh, backing_fd)) => {
						let mut open_flags = sys::FOPEN_NOFLUSH | sys::FOPEN_KEEP_CACHE;
						let mut backing_id = 0i32;

						// Try to set up passthrough if we have a backing fd and the feature is enabled.
						if let Some(fd) = backing_fd
							&& features.passthrough
						{
							match register_passthrough(original_fd, &fd) {
								Ok(id) => {
									open_flags |= sys::FOPEN_PASSTHROUGH;
									backing_id = id;
								},
								Err(error) => {
									tracing::trace!(%error, "passthrough registration failed, falling back");
								},
							}
						}

						SyncResult::Response(Ok(Some(Response::Open(fuse_open_out {
							fh,
							open_flags,
							backing_id,
						}))))
					},
					Err(e) => SyncResult::Response(Err(e)),
				}
			},

			// Try sync read.
			RequestData::Read(data) => {
				match self
					.provider
					.read_sync(data.fh, data.offset, data.size.to_u64().unwrap())
				{
					Err(e) if e.raw_os_error() == Some(ENOSYS) => {
						SyncResult::NeedAsync(request.clone())
					},
					Ok(bytes) => SyncResult::Response(Ok(Some(Response::Read(bytes)))),
					Err(e) => SyncResult::Response(Err(e)),
				}
			},

			// Try sync readlink.
			RequestData::ReadLink => match self.provider.readlink_sync(request.header.nodeid) {
				Err(e) if e.raw_os_error() == Some(ENOSYS) => {
					SyncResult::NeedAsync(request.clone())
				},
				Ok(target) => {
					let target = CString::new(target.as_ref()).unwrap();
					SyncResult::Response(Ok(Some(Response::ReadLink(target))))
				},
				Err(e) => SyncResult::Response(Err(e)),
			},

			// Try sync readdir/readdirplus. When FUSE_NO_OPENDIR_SUPPORT is negotiated,
			// the kernel does not send OPENDIR, so we create a temporary handle.
			RequestData::ReadDir(data) => {
				let (handle, auto_opened) = if features.no_opendir {
					match self.provider.opendir_sync(request.header.nodeid) {
						Err(e) if e.raw_os_error() == Some(ENOSYS) => {
							return SyncResult::NeedAsync(request.clone());
						},
						Ok(fh) => (fh, true),
						Err(e) => return SyncResult::Response(Err(e)),
					}
				} else {
					(data.fh, false)
				};
				let result = match self.provider.readdir_sync(handle) {
					Err(e) if e.raw_os_error() == Some(ENOSYS) => {
						if auto_opened {
							self.provider.close_sync(handle);
						}
						return SyncResult::NeedAsync(request.clone());
					},
					Ok(entries) => build_readdir_response(&self.provider, data, &entries, false),
					Err(e) => Err(e),
				};
				if auto_opened {
					self.provider.close_sync(handle);
				}
				SyncResult::Response(result.map(|r| Some(Response::ReadDir(r))))
			},
			RequestData::ReadDirPlus(data) => {
				let (handle, auto_opened) = if features.no_opendir {
					match self.provider.opendir_sync(request.header.nodeid) {
						Err(e) if e.raw_os_error() == Some(ENOSYS) => {
							return SyncResult::NeedAsync(request.clone());
						},
						Ok(fh) => (fh, true),
						Err(e) => return SyncResult::Response(Err(e)),
					}
				} else {
					(data.fh, false)
				};
				let result = match self.provider.readdir_sync(handle) {
					Err(e) if e.raw_os_error() == Some(ENOSYS) => {
						if auto_opened {
							self.provider.close_sync(handle);
						}
						return SyncResult::NeedAsync(request.clone());
					},
					Ok(entries) => build_readdir_response(&self.provider, data, &entries, true),
					Err(e) => Err(e),
				};
				if auto_opened {
					self.provider.close_sync(handle);
				}
				SyncResult::Response(result.map(|r| Some(Response::ReadDirPlus(r))))
			},

			// OpenDir: when FUSE_NO_OPENDIR_SUPPORT is negotiated, the kernel should not send
			// these. Handle them as a fallback.
			RequestData::OpenDir(..) => match self.provider.opendir_sync(request.header.nodeid) {
				Err(e) if e.raw_os_error() == Some(ENOSYS) => {
					SyncResult::NeedAsync(request.clone())
				},
				Ok(fh) => SyncResult::Response(Ok(Some(Response::OpenDir(fuse_open_out {
					fh,
					open_flags: sys::FOPEN_CACHE_DIR | sys::FOPEN_KEEP_CACHE,
					backing_id: 0,
				})))),
				Err(e) => SyncResult::Response(Err(e)),
			},

			// Try sync getxattr.
			RequestData::GetXattr(data, name) => {
				let Ok(name_str) = name.to_str() else {
					return SyncResult::Response(Err(Error::from_raw_os_error(ENODATA)));
				};
				match self.provider.getxattr_sync(request.header.nodeid, name_str) {
					Err(e) if e.raw_os_error() == Some(ENOSYS) => {
						SyncResult::NeedAsync(request.clone())
					},
					Ok(Some(attr)) => {
						if data.size == 0 {
							let response = fuse_getxattr_out {
								size: attr.len().to_u32().unwrap(),
								padding: 0,
							};
							SyncResult::Response(Ok(Some(Response::GetXattr(
								as_bytes(&response).to_vec(),
							))))
						} else if data.size.to_usize().unwrap() < attr.len() {
							SyncResult::Response(Err(Error::from_raw_os_error(ERANGE)))
						} else {
							SyncResult::Response(Ok(Some(Response::GetXattr(attr.into()))))
						}
					},
					Ok(None) => SyncResult::Response(Err(Error::from_raw_os_error(ENODATA))),
					Err(e) => SyncResult::Response(Err(e)),
				}
			},

			// Try sync listxattrs.
			RequestData::ListXattr(data) => {
				match self.provider.listxattrs_sync(request.header.nodeid) {
					Err(e) if e.raw_os_error() == Some(ENOSYS) => {
						SyncResult::NeedAsync(request.clone())
					},
					Ok(attrs) => {
						let attrs: Vec<u8> = attrs
							.into_iter()
							.flat_map(|s| {
								let mut s = s.into_bytes();
								s.push(0);
								s.into_iter()
							})
							.collect();
						if data.size == 0 {
							let response = fuse_getxattr_out {
								size: attrs.len().to_u32().unwrap(),
								padding: 0,
							};
							SyncResult::Response(Ok(Some(Response::ListXattr(
								as_bytes(&response).to_vec(),
							))))
						} else if data.size.to_usize().unwrap() < attrs.len() {
							SyncResult::Response(Err(Error::from_raw_os_error(ERANGE)))
						} else {
							SyncResult::Response(Ok(Some(Response::ListXattr(attrs))))
						}
					},
					Err(e) => SyncResult::Response(Err(e)),
				}
			},

			// Statfs is always handled synchronously with fixed values.
			RequestData::Statfs => {
				let out = sys::fuse_statfs_out {
					st: sys::fuse_kstatfs {
						blocks: u64::MAX / 2,
						bfree: u64::MAX / 2,
						bavail: u64::MAX / 2,
						files: u64::MAX / 2,
						ffree: u64::MAX / 2,
						bsize: 65536,
						namelen: u32::MAX,
						frsize: 1024,
						padding: 0,
						spare: [0; 6],
					},
				};
				SyncResult::Response(Ok(Some(Response::Statfs(out))))
			},

			// Statx is handled the same as getattr.
			RequestData::Statx(data) => match self.provider.getattr_sync(request.header.nodeid) {
				Err(e) if e.raw_os_error() == Some(ENOSYS) => {
					SyncResult::NeedAsync(request.clone())
				},
				Ok(attr) => {
					let attr_out = make_fuse_attr_out(request.header.nodeid, &attr);
					let out = sys::fuse_statx_out {
						attr_valid: attr_out.attr_valid,
						attr_valid_nsec: attr_out.attr_valid_nsec,
						flags: data.getattr_flags,
						spare: [0; 2],
						stat: sys::fuse_statx {
							mask: 0xffff_ffff,
							ino: attr_out.attr.ino,
							size: attr_out.attr.size,
							blocks: attr_out.attr.blocks,
							blksize: attr_out.attr.blksize,
							attributes: 0,
							nlink: attr_out.attr.nlink,
							uid: attr_out.attr.uid,
							gid: attr_out.attr.gid,
							mode: attr_out.attr.mode.to_u16().unwrap(),
							__spare0: [0],
							attributes_mask: 0xffff_ffff_ffff_ffff,
							atime: sys::fuse_sx_time {
								tv_nsec: 0,
								tv_sec: 0,
								__reserved: 0,
							},
							btime: sys::fuse_sx_time {
								tv_nsec: 0,
								tv_sec: 0,
								__reserved: 0,
							},
							mtime: sys::fuse_sx_time {
								tv_nsec: 0,
								tv_sec: 0,
								__reserved: 0,
							},
							ctime: sys::fuse_sx_time {
								tv_nsec: 0,
								tv_sec: 0,
								__reserved: 0,
							},
							rdev_major: 0,
							rdev_minor: 0,
							dev_major: 0,
							dev_minor: 0,
							__spare2: [0; 14],
						},
					};
					SyncResult::Response(Ok(Some(Response::Statx(out))))
				},
				Err(e) => SyncResult::Response(Err(e)),
			},

			// Unsupported requests return ENOSYS.
			RequestData::Unsupported(opcode) => {
				tracing::trace!(?request.header, %opcode, "unsupported request");
				SyncResult::Response(Err(Error::from_raw_os_error(ENOSYS)))
			},
		}
	}

	async fn handle_request(&self, request: Request) -> Result<Option<Response>> {
		match request.data {
			RequestData::BatchForget(data) => {
				self.handle_batch_forget_request(request.header, data).await
			},
			RequestData::Destroy => Ok(None),
			RequestData::Flush(data) => self.handle_flush_request(request.header, data).await,
			RequestData::Forget(data) => self.handle_forget_request(request.header, data).await,
			RequestData::GetAttr(data) => self.handle_get_attr_request(request.header, data).await,
			RequestData::GetXattr(data, name) => {
				self.handle_get_xattr_request(request.header, data, name)
					.await
			},
			RequestData::Init(data) => self.handle_init_request(request.header, data).await,
			RequestData::ListXattr(data) => {
				self.handle_list_xattr_request(request.header, data).await
			},
			RequestData::Lookup(data) => self.handle_lookup_request(request.header, data).await,
			RequestData::Open(data) => self.handle_open_request(request.header, data).await,
			RequestData::OpenDir(data) => self.handle_open_dir_request(request.header, data).await,
			RequestData::Read(data) => self.handle_read_request(request.header, data).await,
			RequestData::ReadDir(data) => {
				self.handle_read_dir_request(request.header, data, false)
					.await
			},
			RequestData::ReadDirPlus(data) => {
				self.handle_read_dir_request(request.header, data, true)
					.await
			},
			RequestData::ReadLink => self.handle_read_link_request(request.header).await,
			RequestData::Release(data) => self.handle_release_request(request.header, data).await,
			RequestData::ReleaseDir(data) => {
				self.handle_release_dir_request(request.header, data).await
			},
			RequestData::Statfs => self.handle_statfs_request(request.header).await,
			RequestData::Statx(data) => self.handle_statx_request(request.header, data).await,
			RequestData::Interrupt(data) => {
				self.handle_interrupt_request(request.header, data).await
			},

			RequestData::Unsupported(opcode) => {
				self.handle_unsupported_request(request.header, opcode)
					.await
			},
		}
	}

	async fn handle_batch_forget_request(
		&self,
		_header: fuse_in_header,
		_request: fuse_batch_forget_in,
	) -> Result<Option<Response>> {
		Ok(None)
	}

	async fn handle_flush_request(
		&self,
		_header: fuse_in_header,
		_request: fuse_flush_in,
	) -> Result<Option<Response>> {
		Ok(Some(Response::Flush))
	}

	async fn handle_forget_request(
		&self,
		_header: fuse_in_header,
		_request: fuse_forget_in,
	) -> Result<Option<Response>> {
		Ok(None)
	}

	async fn handle_get_attr_request(
		&self,
		header: fuse_in_header,
		_request: fuse_getattr_in,
	) -> Result<Option<Response>> {
		let attr = self.provider.getattr(header.nodeid).await?;
		let out = make_fuse_attr_out(header.nodeid, &attr);
		Ok(Some(Response::GetAttr(out)))
	}

	async fn handle_get_xattr_request(
		&self,
		header: fuse_in_header,
		request: fuse_getxattr_in,
		name: CString,
	) -> Result<Option<Response>> {
		let name = name
			.to_str()
			.map_err(|_| Error::from_raw_os_error(ENODATA))?;
		let attr = self
			.provider
			.getxattr(header.nodeid, name)
			.await?
			.ok_or_else(|| Error::from_raw_os_error(ENODATA))?;

		// If the request size is 0, the driver is requesting the size of the xattr.
		if request.size == 0 {
			let response = fuse_getxattr_out {
				size: attr.len().to_u32().unwrap(),
				padding: 0,
			};
			let response = as_bytes(&response).to_vec();
			Ok(Some(Response::GetXattr(response)))
		} else if request.size.to_usize().unwrap() < attr.len() {
			Err(Error::from_raw_os_error(ERANGE))
		} else {
			Ok(Some(Response::GetXattr(attr.into())))
		}
	}

	async fn handle_init_request(
		&self,
		_header: fuse_in_header,
		request: fuse_init_in,
	) -> Result<Option<Response>> {
		let response = fuse_init_out {
			major: FUSE_KERNEL_VERSION,
			minor: FUSE_KERNEL_MINOR_VERSION,
			max_readahead: request.max_readahead,
			flags: sys::FUSE_DO_READDIRPLUS,
			max_background: 0,
			congestion_threshold: 0,
			max_write: 1024 * 1024,
			time_gran: 0,
			max_pages: 0,
			map_alignment: 0,
			flags2: 0,
			max_stack_depth: 0,
			request_timeout: 0,
			unused: [0; 11],
		};
		Ok(Some(Response::Init(response)))
	}

	async fn handle_list_xattr_request(
		&self,
		header: fuse_in_header,
		request: fuse_getxattr_in,
	) -> Result<Option<Response>> {
		let attrs = self
			.provider
			.listxattrs(header.nodeid)
			.await?
			.into_iter()
			.flat_map(|s| {
				let mut s = s.into_bytes();
				s.push(0);
				s.into_iter()
			})
			.collect::<Vec<_>>();

		if request.size == 0 {
			let response = fuse_getxattr_out {
				size: attrs.len().to_u32().unwrap(),
				padding: 0,
			};
			let response = as_bytes(&response).to_vec();
			Ok(Some(Response::ListXattr(response)))
		} else if request.size.to_usize().unwrap() < attrs.len() {
			Err(Error::from_raw_os_error(ERANGE))
		} else {
			Ok(Some(Response::ListXattr(attrs)))
		}
	}

	async fn handle_lookup_request(
		&self,
		header: fuse_in_header,
		request: CString,
	) -> Result<Option<Response>> {
		let name = request
			.to_str()
			.map_err(|_| Error::from_raw_os_error(ENOENT))?;
		let node = self
			.provider
			.lookup(header.nodeid, name)
			.await?
			.ok_or_else(|| Error::from_raw_os_error(ENOENT))?;
		let attr = self.provider.getattr(node).await?;
		let out = make_fuse_entry_out(node, &attr);
		Ok(Some(Response::Lookup(out)))
	}

	async fn handle_open_request(
		&self,
		header: fuse_in_header,
		_request: fuse_open_in,
	) -> Result<Option<Response>> {
		let fh = self.provider.open(header.nodeid).await?;
		let out = fuse_open_out {
			fh,
			open_flags: sys::FOPEN_NOFLUSH | sys::FOPEN_KEEP_CACHE,
			backing_id: 0,
		};
		Ok(Some(Response::Open(out)))
	}

	async fn handle_open_dir_request(
		&self,
		header: fuse_in_header,
		_request: fuse_open_in,
	) -> Result<Option<Response>> {
		let fh = self.provider.opendir(header.nodeid).await?;
		let out = fuse_open_out {
			fh,
			open_flags: sys::FOPEN_CACHE_DIR | sys::FOPEN_KEEP_CACHE,
			backing_id: 0,
		};
		Ok(Some(Response::OpenDir(out)))
	}

	async fn handle_read_request(
		&self,
		_header: fuse_in_header,
		request: fuse_read_in,
	) -> Result<Option<Response>> {
		let bytes = self
			.provider
			.read(request.fh, request.offset, request.size.to_u64().unwrap())
			.await?;
		Ok(Some(Response::Read(bytes)))
	}

	async fn handle_read_dir_request(
		&self,
		_header: fuse_in_header,
		request: fuse_read_in,
		plus: bool,
	) -> Result<Option<Response>> {
		let entries = self.provider.readdir(request.fh).await?;

		let struct_size = if plus {
			std::mem::size_of::<fuse_direntplus>()
		} else {
			std::mem::size_of::<fuse_dirent>()
		};

		let entries = entries
			.into_iter()
			.enumerate()
			.skip(request.offset.to_usize().unwrap());
		let mut response = Vec::with_capacity(request.size.to_usize().unwrap());
		for (offset, (name, node)) in entries {
			let attr = self.provider.getattr(node).await?;
			let name = name.into_bytes();
			let padding = (8 - (struct_size + name.len()) % 8) % 8;
			let entry_size = struct_size + name.len() + padding;
			if response.len() + entry_size > request.size.to_usize().unwrap() {
				break;
			}

			let type_ = match attr.typ {
				FileType::Directory => S_IFDIR,
				FileType::File { .. } => S_IFREG,
				FileType::Symlink => S_IFLNK,
			};

			let entry = fuse_dirent {
				ino: node,
				off: offset.to_u64().unwrap() + 1,
				namelen: name.len().to_u32().unwrap(),
				type_,
			};

			if plus {
				let entry = fuse_direntplus {
					entry_out: make_fuse_entry_out(node, &attr),
					dirent: entry,
				};
				response.extend_from_slice(as_bytes(&entry));
			} else {
				response.extend_from_slice(as_bytes(&entry));
			}
			response.extend_from_slice(&name);
			response.extend((0..padding).map(|_| 0));
		}

		if plus {
			Ok(Some(Response::ReadDirPlus(response)))
		} else {
			Ok(Some(Response::ReadDir(response)))
		}
	}

	async fn handle_read_link_request(&self, header: fuse_in_header) -> Result<Option<Response>> {
		let target = self.provider.readlink(header.nodeid).await?;
		let target = CString::new(target.as_ref()).unwrap();
		Ok(Some(Response::ReadLink(target)))
	}

	async fn handle_release_request(
		&self,
		_header: fuse_in_header,
		request: fuse_release_in,
	) -> Result<Option<Response>> {
		self.provider.close(request.fh).await;
		Ok(Some(Response::Release))
	}

	async fn handle_release_dir_request(
		&self,
		_header: fuse_in_header,
		request: fuse_release_in,
	) -> Result<Option<Response>> {
		self.provider.close(request.fh).await;
		Ok(Some(Response::ReleaseDir))
	}

	async fn handle_statfs_request(
		&self,
		_header: sys::fuse_in_header,
	) -> Result<Option<Response>> {
		let out = sys::fuse_statfs_out {
			st: sys::fuse_kstatfs {
				blocks: u64::MAX / 2,
				bfree: u64::MAX / 2,
				bavail: u64::MAX / 2,
				files: u64::MAX / 2,
				ffree: u64::MAX / 2,
				bsize: 65536,
				namelen: u32::MAX,
				frsize: 1024,
				padding: 0,
				spare: [0; 6],
			},
		};
		Ok(Some(Response::Statfs(out)))
	}

	async fn handle_statx_request(
		&self,
		header: sys::fuse_in_header,
		request: sys::fuse_statx_in,
	) -> Result<Option<Response>> {
		let Some(Response::GetAttr(attr)) = self
			.handle_get_attr_request(header, {
				sys::fuse_getattr_in {
					getattr_flags: request.getattr_flags,
					dummy: 0,
					fh: request.fh,
				}
			})
			.await?
		else {
			return Ok(None);
		};
		let out = sys::fuse_statx_out {
			attr_valid: attr.attr_valid,
			attr_valid_nsec: attr.attr_valid_nsec,
			flags: request.getattr_flags,
			spare: [0; 2],
			stat: sys::fuse_statx {
				mask: 0xffff_ffff,
				ino: attr.attr.ino,
				size: attr.attr.size,
				blocks: attr.attr.blocks,
				blksize: attr.attr.blksize,
				attributes: 0,
				nlink: attr.attr.nlink,
				uid: attr.attr.uid,
				gid: attr.attr.gid,
				mode: attr.attr.mode.to_u16().unwrap(),
				__spare0: [0],
				attributes_mask: 0xffff_ffff_ffff_ffff,
				atime: sys::fuse_sx_time {
					tv_nsec: 0,
					tv_sec: 0,
					__reserved: 0,
				},
				btime: sys::fuse_sx_time {
					tv_nsec: 0,
					tv_sec: 0,
					__reserved: 0,
				},
				mtime: sys::fuse_sx_time {
					tv_nsec: 0,
					tv_sec: 0,
					__reserved: 0,
				},
				ctime: sys::fuse_sx_time {
					tv_nsec: 0,
					tv_sec: 0,
					__reserved: 0,
				},
				rdev_major: 0,
				rdev_minor: 0,
				dev_major: 0,
				dev_minor: 0,
				__spare2: [0; 14],
			},
		};
		Ok(Some(Response::Statx(out)))
	}

	async fn handle_interrupt_request(
		&self,
		_header: fuse_in_header,
		_request: fuse_interrupt_in,
	) -> Result<Option<Response>> {
		Ok(None)
	}

	async fn handle_unsupported_request(
		&self,
		header: fuse_in_header,
		request: u32,
	) -> Result<Option<Response>> {
		tracing::trace!(?header, %request, "unsupported request");
		Err(Error::from_raw_os_error(ENOSYS))
	}

	async fn mount(path: &Path) -> Result<Arc<OwnedFd>> {
		// Create the socket pair. Both sockets get CLOEXEC by default.
		let (sock_parent, sock_child) = rustix::net::socketpair(
			rustix::net::AddressFamily::UNIX,
			rustix::net::SocketType::STREAM,
			rustix::net::SocketFlags::CLOEXEC,
			None,
		)?;

		let child_fd_raw = sock_child.as_raw_fd();

		let uid = rustix::process::getuid().as_raw();
		let gid = rustix::process::getgid().as_raw();
		let options = format!("rootmode=40755,user_id={uid},group_id={gid},default_permissions");

		// Spawn fusermount3, passing the child socket fd via _FUSE_COMMFD.
		// Safety: The pre_exec closure only calls async-signal-safe operations.
		let mut child = unsafe {
			std::process::Command::new("fusermount3")
				.args(["-o", &options, "--"])
				.arg(path)
				.env("_FUSE_COMMFD", child_fd_raw.to_string())
				.stdin(std::process::Stdio::null())
				.stdout(std::process::Stdio::null())
				.stderr(std::process::Stdio::null())
				.pre_exec(move || {
					// Clear CLOEXEC on the child socket so fusermount3 inherits it.
					let fd = rustix::fd::BorrowedFd::borrow_raw(child_fd_raw);
					rustix::io::fcntl_setfd(fd, rustix::io::FdFlags::empty())?;
					Ok(())
				})
				.spawn()
				.map_err(|e| Error::other(format!("failed to spawn fusermount3: {e}")))?
		};

		// Close the child end in the parent.
		drop(sock_child);

		// Receive the FUSE fd from the parent socket via SCM_RIGHTS.
		let mut space = [MaybeUninit::<u8>::uninit(); rustix::cmsg_space!(ScmRights(1))];
		let mut cmsg_buffer = rustix::net::RecvAncillaryBuffer::new(&mut space);
		let mut data_buf = [0u8; 8];
		let mut iov = [std::io::IoSliceMut::new(&mut data_buf)];
		let msg = rustix::net::recvmsg(
			&sock_parent,
			&mut iov,
			&mut cmsg_buffer,
			rustix::net::RecvFlags::empty(),
		)?;

		if msg.bytes == 0 {
			// fusermount3 closed the socket without sending an fd.
			let status = child.wait()?;
			return Err(Error::other(format!(
				"failed to read the control message from fusermount3 (exit code {})",
				status.code().unwrap_or(-1)
			)));
		}

		// Extract the fd from SCM_RIGHTS.
		let mut fuse_fd = None;
		for cmsg in cmsg_buffer.drain() {
			if let rustix::net::RecvAncillaryMessage::ScmRights(fds) = cmsg {
				for fd in fds {
					fuse_fd = Some(fd);
				}
			}
		}

		let fd = fuse_fd.ok_or_else(|| Error::other("missing the control message"))?;

		// Set CLOEXEC on the FUSE fd.
		rustix::io::fcntl_setfd(&fd, rustix::io::FdFlags::CLOEXEC)?;

		// Wait for fusermount3 to complete.
		child.wait()?;

		Ok(Arc::new(fd))
	}
}

/// Build a readdir response from a list of entries, using sync getattr.
fn build_readdir_response<P: Provider>(
	provider: &P,
	request: &fuse_read_in,
	entries: &[(String, u64)],
	plus: bool,
) -> Result<Vec<u8>> {
	let struct_size = if plus {
		std::mem::size_of::<fuse_direntplus>()
	} else {
		std::mem::size_of::<fuse_dirent>()
	};

	let entries = entries
		.iter()
		.enumerate()
		.skip(request.offset.to_usize().unwrap());
	let mut response = Vec::with_capacity(request.size.to_usize().unwrap());
	for (offset, (name, node)) in entries {
		let node = *node;
		let attr = provider.getattr_sync(node)?;
		let name = name.as_bytes();
		let padding = (8 - (struct_size + name.len()) % 8) % 8;
		let entry_size = struct_size + name.len() + padding;
		if response.len() + entry_size > request.size.to_usize().unwrap() {
			break;
		}

		let type_ = match attr.typ {
			FileType::Directory => S_IFDIR,
			FileType::File { .. } => S_IFREG,
			FileType::Symlink => S_IFLNK,
		};

		let entry = fuse_dirent {
			ino: node,
			off: offset.to_u64().unwrap() + 1,
			namelen: name.len().to_u32().unwrap(),
			type_,
		};

		if plus {
			let entry = fuse_direntplus {
				entry_out: make_fuse_entry_out(node, &attr),
				dirent: entry,
			};
			response.extend_from_slice(as_bytes(&entry));
		} else {
			response.extend_from_slice(as_bytes(&entry));
		}
		response.extend_from_slice(name);
		response.extend((0..padding).map(|_| 0));
	}

	Ok(response)
}

/// Build a `fuse_attr_out` from a node id and attributes.
fn make_fuse_attr_out(node: u64, attr: &crate::Attrs) -> fuse_attr_out {
	let (size, mode) = match attr.typ {
		FileType::Directory => (0, S_IFDIR | 0o555),
		FileType::File { executable, size } => (
			size,
			S_IFREG | 0o444 | (if executable { 0o111 } else { 0o000 }),
		),
		FileType::Symlink => (0, S_IFLNK | 0o444),
	};
	fuse_attr_out {
		attr_valid: u64::MAX,
		attr_valid_nsec: 0,
		attr: fuse_attr {
			ino: node,
			size,
			blocks: 0,
			atime: attr.atime.secs,
			atimensec: attr.atime.nanos,
			mtime: attr.mtime.secs,
			mtimensec: attr.mtime.nanos,
			ctime: attr.ctime.secs,
			ctimensec: attr.ctime.nanos,
			mode,
			nlink: 1,
			uid: attr.uid,
			gid: attr.gid,
			rdev: 0,
			blksize: 512,
			flags: 0,
		},
		dummy: 0,
	}
}

/// Build a `fuse_entry_out` from a node id and attributes.
fn make_fuse_entry_out(node: u64, attr: &crate::Attrs) -> fuse_entry_out {
	let attr_out = make_fuse_attr_out(node, attr);
	fuse_entry_out {
		nodeid: node,
		generation: 0,
		entry_valid: u64::MAX,
		attr_valid: u64::MAX,
		entry_valid_nsec: 0,
		attr_valid_nsec: 0,
		attr: attr_out.attr,
	}
}

/// Clone a FUSE device fd using `FUSE_DEV_IOC_CLONE`.
fn clone_fuse_fd(fd: &OwnedFd) -> Result<OwnedFd> {
	// Open a new /dev/fuse fd.
	let new_fd = std::fs::OpenOptions::new()
		.read(true)
		.write(true)
		.open("/dev/fuse")?;
	let new_fd = OwnedFd::from(new_fd);

	// Clone the original fd onto the new fd.
	let old_fd_raw: u32 = fd.as_raw_fd().cast_unsigned();

	// Safety: FUSE_DEV_IOC_CLONE is a valid ioctl for /dev/fuse fds.
	unsafe {
		rustix::ioctl::ioctl(
			&new_fd,
			rustix::ioctl::Setter::<FUSE_DEV_IOC_CLONE, u32>::new(old_fd_raw),
		)?;
	}

	Ok(new_fd)
}

/// Register a backing file for passthrough and return the backing id.
fn register_passthrough(fuse_fd: &OwnedFd, backing_fd: &OwnedFd) -> Result<i32> {
	let map = fuse_backing_map {
		fd: backing_fd.as_raw_fd(),
		flags: 0,
		padding: 0,
	};

	// Safety: FUSE_DEV_IOC_BACKING_OPEN is a valid ioctl for the FUSE device fd.
	let backing_id = unsafe { rustix::ioctl::ioctl(fuse_fd, BackingOpenIoctl(map))? };

	Ok(backing_id)
}

/// The worker thread event loop. Tries to use `io_uring`, and falls back to blocking reads.
fn worker_thread_loop<P>(
	server: &Server<P>,
	fuse_fd: &OwnedFd,
	original_fd: &OwnedFd,
	stop_flag: &AtomicBool,
	features: &Features,
	runtime_handle: &tokio::runtime::Handle,
) where
	P: Provider + Send + Sync + 'static,
{
	match io_uring::IoUring::builder().build(256) {
		Ok(mut ring) => {
			worker_thread_loop_uring(
				server,
				fuse_fd,
				original_fd,
				stop_flag,
				features,
				&mut ring,
				runtime_handle,
			);
		},
		Err(error) => {
			tracing::trace!(%error, "io_uring unavailable, falling back to blocking loop");
			worker_thread_loop_blocking(
				server,
				fuse_fd,
				original_fd,
				stop_flag,
				features,
				runtime_handle,
			);
		},
	}
}

/// Worker thread loop using `io_uring` Read/Write SQEs for all FUSE I/O. Multiple Read SQEs are
/// kept in flight for batching: when the kernel queues several FUSE requests, their Read CQEs
/// complete together, allowing batch processing before responses are submitted.
#[allow(clippy::too_many_arguments)]
fn worker_thread_loop_uring<P>(
	server: &Server<P>,
	fuse_fd: &OwnedFd,
	original_fd: &OwnedFd,
	stop_flag: &AtomicBool,
	features: &Features,
	ring: &mut io_uring::IoUring,
	runtime_handle: &tokio::runtime::Handle,
) where
	P: Provider + Send + Sync + 'static,
{
	use {io_uring::opcode, io_uring::types, std::collections::HashMap};

	// Create an eventfd for async completion notification.
	let event_fd = rustix::event::eventfd(0, rustix::event::EventfdFlags::NONBLOCK)
		.expect("failed to create eventfd");

	// Try to register file descriptors with io_uring for faster kernel fd lookups. Registered
	// fds use Fixed indices instead of raw fd numbers, avoiding per-operation fd table lookups.
	// Layout: Fixed(0) = fuse_fd (read + write), Fixed(1) = event_fd (poll).
	let use_fixed = ring
		.submitter()
		.register_files(&[fuse_fd.as_raw_fd(), event_fd.as_raw_fd()])
		.is_ok();

	let (async_sender, async_receiver) =
		crossbeam_channel::unbounded::<(u64, Result<Option<Response>>)>();

	// Allocate one read buffer per concurrent Read SQE. The buffer only needs to hold FUSE
	// request headers and metadata (never write data), so 64KB is more than sufficient.
	let buf_size = 64 * 1024;
	let mut read_bufs: Vec<Vec<u8>> = (0..READ_CONCURRENCY).map(|_| vec![0u8; buf_size]).collect();
	let mut free_bufs: Vec<u64> = (0..READ_CONCURRENCY).collect();

	// Pending writes: maps write token to the serialized response buffer.
	let mut pending_writes: HashMap<u64, Vec<u8>> = HashMap::new();
	let mut write_seq: u64 = 0;

	// State tracking for the in-flight eventfd PollAdd.
	let mut eventfd_poll_pending = false;

	// Helper macro to build an SQE with either a registered Fixed fd or a raw Fd, depending on
	// whether file registration succeeded. This avoids the sealed `Target` type.
	macro_rules! build_sqe {
		(read, $fixed_idx:expr, $raw_fd:expr, $ptr:expr, $len:expr) => {
			if use_fixed {
				opcode::Read::new(types::Fixed($fixed_idx), $ptr, $len).build()
			} else {
				opcode::Read::new(types::Fd($raw_fd), $ptr, $len).build()
			}
		};
		(poll_add, $fixed_idx:expr, $raw_fd:expr, $mask:expr) => {
			if use_fixed {
				opcode::PollAdd::new(types::Fixed($fixed_idx), $mask).build()
			} else {
				opcode::PollAdd::new(types::Fd($raw_fd), $mask).build()
			}
		};
	}

	loop {
		if stop_flag.load(Ordering::Relaxed) {
			break;
		}

		// Submit Read SQEs for all free buffers.
		while let Some(buf_idx) = free_bufs.pop() {
			let buf = &mut read_bufs[buf_idx.to_usize().unwrap()];
			let sqe = build_sqe!(
				read,
				0,
				fuse_fd.as_raw_fd(),
				buf.as_mut_ptr(),
				buf.len().to_u32().unwrap()
			)
			.user_data(buf_idx);
			unsafe {
				ring.submission()
					.push(&sqe)
					.expect("failed to push Read SQE");
			}
		}

		// Submit PollAdd for the eventfd if not already pending.
		if !eventfd_poll_pending {
			let sqe =
				build_sqe!(poll_add, 1, event_fd.as_raw_fd(), POLLIN).user_data(EVENTFD_TOKEN);
			unsafe {
				ring.submission()
					.push(&sqe)
					.expect("failed to push eventfd PollAdd");
			}
			eventfd_poll_pending = true;
		}

		// Submit all pending SQEs and wait for at least one completion.
		if ring.submit_and_wait(1).is_err() {
			if stop_flag.load(Ordering::Relaxed) {
				break;
			}
			continue;
		}

		// Drain all completions. Collect completed reads into a batch so that cache prefetching
		// from earlier requests (e.g. readdir) benefits later ones (e.g. getattr).
		let mut batch: Vec<Request> = Vec::new();
		let cqes: Vec<io_uring::cqueue::Entry> = ring.completion().collect();
		for cqe in cqes {
			let token = cqe.user_data();
			let result = cqe.result();

			if token < READ_CONCURRENCY {
				// Read completion. Deserialize and add to batch, then return the buffer.
				if result < 0 {
					let errno = -result;
					if errno == rustix::io::Errno::NODEV.raw_os_error() {
						return;
					}
					free_bufs.push(token);
					continue;
				}
				let n = result.to_usize().unwrap();
				match Server::<P>::deserialize_request(&read_bufs[token.to_usize().unwrap()][..n]) {
					Ok(r) => batch.push(r),
					Err(error) => {
						tracing::error!(%error, "failed to deserialize request");
					},
				}
				free_bufs.push(token);
			} else if token == EVENTFD_TOKEN {
				eventfd_poll_pending = false;

				// Clear the eventfd counter.
				let mut buf = [0u8; 8];
				rustix::io::read(&event_fd, &mut buf).ok();

				// Drain all async results and submit Write SQEs for each.
				while let Ok((unique, result)) = async_receiver.try_recv() {
					submit_response_write(
						ring,
						fuse_fd,
						use_fixed,
						unique,
						result,
						&mut pending_writes,
						&mut write_seq,
					);
				}
			} else if token >= WRITE_TOKEN_BASE {
				// Write completion. Drop the buffer.
				pending_writes.remove(&token);
			}
		}

		// Process all batched requests, then submit their Write SQEs.
		for request in &batch {
			process_fuse_request(
				server,
				request,
				original_fd,
				fuse_fd,
				features,
				ring,
				use_fixed,
				&async_sender,
				&event_fd,
				runtime_handle,
				&mut pending_writes,
				&mut write_seq,
			);
		}
	}
}

/// Process a single FUSE request: try sync handling, fall back to async, submit response.
#[allow(clippy::too_many_arguments)]
fn process_fuse_request<P>(
	server: &Server<P>,
	request: &Request,
	original_fd: &OwnedFd,
	fuse_fd: &OwnedFd,
	features: &Features,
	ring: &mut io_uring::IoUring,
	use_fixed: bool,
	async_sender: &crossbeam_channel::Sender<(u64, Result<Option<Response>>)>,
	event_fd: &OwnedFd,
	runtime_handle: &tokio::runtime::Handle,
	pending_writes: &mut std::collections::HashMap<u64, Vec<u8>>,
	write_seq: &mut u64,
) where
	P: Provider + Send + Sync + 'static,
{
	let unique = request.header.unique;

	match server.try_handle_sync(request, original_fd, features) {
		SyncResult::Response(result) => {
			submit_response_write(
				ring,
				fuse_fd,
				use_fixed,
				unique,
				result,
				pending_writes,
				write_seq,
			);
		},
		SyncResult::NoResponse => {},
		SyncResult::NeedAsync(request) => {
			let server = server.clone();
			let sender = async_sender.clone();
			let event_fd_raw = event_fd.as_raw_fd();
			runtime_handle.spawn(async move {
				let result = server
					.handle_request(request.clone())
					.await
					.inspect_err(|error| {
						let opcode = request.header.opcode;
						if !is_expected_error(opcode, error.raw_os_error()) {
							tracing::error!(?error, ?opcode, "unexpected error");
						}
					});
				sender.send((unique, result)).ok();
				// Safety: The event_fd outlives this async task because the worker thread joins
				// before the server is dropped.
				let fd = unsafe { rustix::fd::BorrowedFd::borrow_raw(event_fd_raw) };
				rustix::io::write(fd, &1u64.to_ne_bytes()).ok();
			});
		},
	}
}

/// Submit a Write SQE for a response through `io_uring`.
#[allow(clippy::too_many_arguments)]
fn submit_response_write(
	ring: &mut io_uring::IoUring,
	fuse_fd: &OwnedFd,
	use_fixed: bool,
	unique: u64,
	result: Result<Option<Response>>,
	pending_writes: &mut std::collections::HashMap<u64, Vec<u8>>,
	write_seq: &mut u64,
) {
	use {io_uring::opcode, io_uring::types};

	let buf = match result {
		Ok(Some(response)) => serialize_response(unique, &response),
		Ok(None) => return,
		Err(error) => {
			if !is_expected_error(0, error.raw_os_error()) {
				tracing::error!(?error, "unexpected error");
			}
			let errno = error.raw_os_error().unwrap_or(ENOSYS);
			serialize_error(unique, errno)
		},
	};

	let token = WRITE_TOKEN_BASE + *write_seq;
	*write_seq += 1;

	let sqe = if use_fixed {
		opcode::Write::new(types::Fixed(0), buf.as_ptr(), buf.len().to_u32().unwrap()).build()
	} else {
		opcode::Write::new(
			types::Fd(fuse_fd.as_raw_fd()),
			buf.as_ptr(),
			buf.len().to_u32().unwrap(),
		)
		.build()
	}
	.user_data(token);

	// Try to push the Write SQE. If the SQ is full, flush it first.
	let pushed = unsafe {
		ring.submission().push(&sqe).is_ok() || {
			ring.submit().ok();
			ring.submission().push(&sqe).is_ok()
		}
	};

	if pushed {
		pending_writes.insert(token, buf);
	} else {
		// SQ still full after flush. Fall back to synchronous write.
		rustix::io::write(fuse_fd, &buf).ok();
	}
}

/// Serialize a response into a single buffer (header + body) for `io_uring` write.
fn serialize_response(unique: u64, response: &Response) -> Vec<u8> {
	let body: &[u8] = match response {
		Response::Flush | Response::Release | Response::ReleaseDir => &[],
		Response::GetAttr(data) => as_bytes(data),
		Response::Init(data) => as_bytes(data),
		Response::Lookup(data) => as_bytes(data),
		Response::Open(data) | Response::OpenDir(data) => as_bytes(data),
		Response::Read(data) => data,
		Response::ReadDir(data)
		| Response::ReadDirPlus(data)
		| Response::GetXattr(data)
		| Response::ListXattr(data) => data.as_slice(),
		Response::ReadLink(data) => data.as_bytes(),
		Response::Statfs(data) => as_bytes(data),
		Response::Statx(data) => as_bytes(data),
	};
	let len = std::mem::size_of::<fuse_out_header>() + body.len();
	let header = fuse_out_header {
		unique,
		len: len.to_u32().unwrap(),
		error: 0,
	};
	let header_bytes = as_bytes(&header);
	let mut buf = Vec::with_capacity(len);
	buf.extend_from_slice(header_bytes);
	buf.extend_from_slice(body);
	buf
}

/// Serialize an error response into a single buffer for `io_uring` write.
fn serialize_error(unique: u64, error: i32) -> Vec<u8> {
	let len = std::mem::size_of::<fuse_out_header>();
	let header = fuse_out_header {
		unique,
		len: len.to_u32().unwrap(),
		error: -error,
	};
	as_bytes(&header).to_vec()
}

/// The blocking fallback worker thread event loop.
fn worker_thread_loop_blocking<P>(
	server: &Server<P>,
	fuse_fd: &OwnedFd,
	original_fd: &OwnedFd,
	stop_flag: &AtomicBool,
	features: &Features,
	runtime_handle: &tokio::runtime::Handle,
) where
	P: Provider + Send + Sync + 'static,
{
	let (async_sender, async_receiver) =
		crossbeam_channel::unbounded::<(u64, Result<Option<Response>>)>();

	// Create an eventfd for async completion notification.
	let event_fd = rustix::event::eventfd(0, rustix::event::EventfdFlags::NONBLOCK)
		.expect("failed to create eventfd");

	let mut buffer = vec![0u8; 64 * 1024];

	loop {
		if stop_flag.load(Ordering::Relaxed) {
			break;
		}

		// Drain any pending async results first.
		while let Ok((unique, result)) = async_receiver.try_recv() {
			match result {
				Ok(Some(response)) => {
					write_response(fuse_fd.as_fd(), unique, &response).ok();
				},
				Ok(None) => (),
				Err(error) => {
					let errno = error.raw_os_error().unwrap_or(ENOSYS);
					write_error(fuse_fd.as_fd(), unique, errno).ok();
				},
			}
		}

		// Read a request.
		let n = match rustix::io::read(fuse_fd, &mut buffer[..]) {
			Ok(n) => n,
			Err(rustix::io::Errno::NOENT | rustix::io::Errno::INTR | rustix::io::Errno::AGAIN) => {
				continue;
			},
			Err(rustix::io::Errno::NODEV) => return,
			Err(error) => {
				tracing::error!(%error, "FUSE read error");
				return;
			},
		};
		let request = match Server::<P>::deserialize_request(&buffer[..n]) {
			Ok(r) => r,
			Err(error) => {
				tracing::error!(%error, "failed to deserialize request");
				continue;
			},
		};

		let unique = request.header.unique;

		// Try sync handling.
		match server.try_handle_sync(&request, original_fd, features) {
			SyncResult::Response(result) => match result {
				Ok(Some(response)) => {
					write_response(fuse_fd.as_fd(), unique, &response)
						.inspect_err(|error| {
							tracing::error!(?error, "failed to write the response");
						})
						.ok();
				},
				Ok(None) => (),
				Err(error) => {
					if !is_expected_error(request.header.opcode, error.raw_os_error()) {
						tracing::error!(?error, opcode = ?request.header.opcode, "unexpected error");
					}
					let errno = error.raw_os_error().unwrap_or(ENOSYS);
					write_error(fuse_fd.as_fd(), unique, errno)
						.inspect_err(|error| {
							tracing::error!(?error, "failed to write the error");
						})
						.ok();
				},
			},
			SyncResult::NoResponse => {},
			SyncResult::NeedAsync(request) => {
				let server = server.clone();
				let sender = async_sender.clone();
				let event_fd_raw = event_fd.as_raw_fd();
				runtime_handle.spawn(async move {
					let result =
						server
							.handle_request(request.clone())
							.await
							.inspect_err(|error| {
								let opcode = request.header.opcode;
								if !is_expected_error(opcode, error.raw_os_error()) {
									tracing::error!(?error, ?opcode, "unexpected error");
								}
							});
					sender.send((unique, result)).ok();
					// Safety: The event_fd outlives this async task.
					let fd = unsafe { rustix::fd::BorrowedFd::borrow_raw(event_fd_raw) };
					rustix::io::write(fd, &1u64.to_ne_bytes()).ok();
				});
			},
		}
	}
}

/// Read a `#[repr(C)]`, `Copy` struct from the beginning of a byte slice.
fn read_data<T: Copy>(request_data: &[u8]) -> Result<T> {
	if request_data.len() < std::mem::size_of::<T>() {
		return Err(Error::other("failed to deserialize the request data"));
	}
	// Safety: T is #[repr(C)] and Copy. We verified the slice is large enough.
	Ok(unsafe { std::ptr::read_unaligned(request_data.as_ptr().cast::<T>()) })
}

/// View a `#[repr(C)]`, `Copy` struct as a byte slice.
fn as_bytes<T: Copy>(value: &T) -> &[u8] {
	// Safety: T is #[repr(C)] and Copy with no padding that could leak data.
	unsafe {
		std::slice::from_raw_parts(
			std::ptr::from_ref(value).cast::<u8>(),
			std::mem::size_of::<T>(),
		)
	}
}

fn write_error(fd: BorrowedFd<'_>, unique: u64, error: i32) -> std::io::Result<()> {
	let len = std::mem::size_of::<fuse_out_header>();
	let header = fuse_out_header {
		unique,
		len: len.to_u32().unwrap(),
		error: -error,
	};
	let header = as_bytes(&header);
	let iov = [IoSlice::new(header)];
	rustix::io::writev(fd, &iov)?;
	Ok(())
}

fn write_response(fd: BorrowedFd<'_>, unique: u64, response: &Response) -> std::io::Result<()> {
	let data = match response {
		Response::Flush | Response::Release | Response::ReleaseDir => &[],
		Response::GetAttr(data) => as_bytes(data),
		Response::Init(data) => as_bytes(data),
		Response::Lookup(data) => as_bytes(data),
		Response::Open(data) | Response::OpenDir(data) => as_bytes(data),
		Response::Read(data) => data,
		Response::ReadDir(data)
		| Response::ReadDirPlus(data)
		| Response::GetXattr(data)
		| Response::ListXattr(data) => data.as_slice(),
		Response::ReadLink(data) => data.as_bytes(),
		Response::Statfs(data) => as_bytes(data),
		Response::Statx(data) => as_bytes(data),
	};
	let len = std::mem::size_of::<fuse_out_header>() + data.len();
	let header = fuse_out_header {
		unique,
		len: len.to_u32().unwrap(),
		error: 0,
	};
	let header = as_bytes(&header);
	let iov = [IoSlice::new(header), IoSlice::new(data)];
	rustix::io::writev(fd, &iov)?;
	Ok(())
}

impl<P> Clone for Server<P> {
	fn clone(&self) -> Self {
		Self(self.0.clone())
	}
}

impl<P> Deref for Server<P> {
	type Target = Inner<P>;

	fn deref(&self) -> &Self::Target {
		&self.0
	}
}

pub async fn unmount(path: &Path) -> Result<()> {
	let output = tokio::process::Command::new("fusermount3")
		.args(["-uz"])
		.arg(path)
		.stdin(std::process::Stdio::null())
		.stdout(std::process::Stdio::null())
		.stderr(std::process::Stdio::piped())
		.output()
		.await?;
	if !output.status.success() {
		let stderr = String::from_utf8_lossy(&output.stderr);
		return Err(Error::other(format!("failed to unmount: {stderr}")));
	}
	Ok(())
}

// There are a small number of "expected" error conditions, where the request correctly returns an error, but not due to a filesystem error. These are:
// - lookups that return ENOENT (None)
// - getxattrs that return ENODATA (None)
// - getxattr/listxattr that return ERANGE (blame the caller, they provided garbage data)
// - ENOSYS: only returned when the filesystem doesn't support a request.
fn is_expected_error(opcode: sys::fuse_opcode, error: Option<i32>) -> bool {
	(opcode == sys::fuse_opcode_FUSE_LOOKUP && error == Some(ENOENT))
		| (opcode == sys::fuse_opcode_FUSE_GETXATTR && error == Some(ENODATA))
		| (opcode == sys::fuse_opcode_FUSE_GETXATTR && error == Some(ERANGE))
		| (opcode == sys::fuse_opcode_FUSE_LISTXATTR && error == Some(ERANGE))
		| (error == Some(ENOSYS))
}
